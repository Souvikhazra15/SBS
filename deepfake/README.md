# Deepfake Detection Using Deep Learning (ResNext and LSTM)

> A comprehensive deepfake detection system using transfer learning with ResNext CNN and LSTM networks.

[![GitHub](https://img.shields.io/badge/GitHub-Zala0007-lightgrey?logo=github)](https://github.com/Zala0007/deepfake)
[![Python](https://img.shields.io/badge/Python-3.6%2B-blue?logo=python)](https://www.python.org/)
[![Django](https://img.shields.io/badge/Django-5.0%2B-green?logo=django)](https://www.djangoproject.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow)](#license)

## üìã Table of Contents

- [Introduction](#introduction)
- [Features](#features)
- [Project Structure](#project-structure)
- [System Architecture](#system-architecture)
- [Available Models](#available-models)
- [Prerequisites](#prerequisites)
- [Quick Start](#quick-start)
- [Detailed Installation](#detailed-installation)
- [Running the Application](#running-the-application)
- [Docker Setup](#docker-setup)
- [Model Training](#model-training)
- [Results](#results)
- [Troubleshooting](#troubleshooting)
- [License](#license)

---

## üéØ Introduction

This project aims to detect video deepfakes using deep learning techniques combining **ResNext CNN** and **LSTM networks**. 

The approach uses **transfer learning** where:
1. Pretrained **ResNext CNN** extracts feature vectors from video frames
2. **LSTM layers** are trained on these features to detect temporal inconsistencies
3. The model achieves **97% accuracy** on test datasets

**Key Achievement**: Can detect deepfakes with 97% accuracy using just 100 frames

---

## ‚ú® Features

- ‚úÖ **Web-based Interface**: Django application for easy video upload and prediction
- ‚úÖ **High Accuracy**: Up to 97% detection accuracy
- ‚úÖ **Multiple Model Options**: Choose between speed vs accuracy (10, 20, or 100 frames)
- ‚úÖ **Real-time Processing**: Analyze videos in seconds to minutes
- ‚úÖ **GPU Acceleration**: CUDA support for fast inference
- ‚úÖ **Docker Support**: Containerized deployment ready
- ‚úÖ **Face Detection**: Integrated face-api.js for visualization
- ‚úÖ **Responsive UI**: Bootstrap-based responsive design

---

## üìÅ Project Structure

```
deepfake/
‚îú‚îÄ‚îÄ Django Application/          # Web application (main)
‚îÇ   ‚îú‚îÄ‚îÄ ml_app/                 # Django app with ML logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ views.py            # Application views and prediction logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models.py           # Django models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ forms.py            # Form definitions
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ urls.py             # URL routing
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ templates/          # HTML templates
‚îÇ   ‚îú‚îÄ‚îÄ project_settings/        # Django configuration
‚îÇ   ‚îú‚îÄ‚îÄ static/                 # CSS, JavaScript, Face-API models
‚îÇ   ‚îú‚îÄ‚îÄ media/                  # Uploaded videos and images
‚îÇ   ‚îú‚îÄ‚îÄ models/                 # Trained PyTorch models
‚îÇ   ‚îú‚îÄ‚îÄ manage.py               # Django management script
‚îÇ   ‚îú‚îÄ‚îÄ db.sqlite3              # Database
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt         # Python dependencies
‚îÇ
‚îú‚îÄ‚îÄ Model Creation/              # Model development and training
‚îÇ   ‚îú‚îÄ‚îÄ Predict.ipynb           # Prediction notebook
‚îÇ   ‚îú‚îÄ‚îÄ Model_and_train_csv.ipynb # Training notebook
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.ipynb      # Data preprocessing
‚îÇ   ‚îú‚îÄ‚îÄ Helpers/                # Helper scripts and notebooks
‚îÇ   ‚îî‚îÄ‚îÄ labels/                 # Training labels and metadata
‚îÇ
‚îú‚îÄ‚îÄ MODEL_GUIDE.md              # Model selection and usage guide
‚îú‚îÄ‚îÄ README.md                   # Original README
‚îî‚îÄ‚îÄ LICENSE                     # License information
```

---

## üèóÔ∏è System Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                                 ‚îÇ
‚îÇ              User Interface (Django Web App)                    ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                                 ‚îÇ
‚îÇ            Video Upload & Frame Extraction                      ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                                 ‚îÇ
‚îÇ   ResNext CNN (Pretrained)    Feature Extraction               ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                                 ‚îÇ
‚îÇ              LSTM Network          Temporal Analysis            ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                                 ‚îÇ
‚îÇ         Deepfake Classification (Real or Fake)                 ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìä Available Models

| Model | Frames | Accuracy | Speed | Use Case |
|-------|--------|----------|-------|----------|
| `model_84_acc_10_frames_final_data.pt` | 10 | 84% | ‚ö° Very Fast | Quick testing |
| `model_87_acc_20_frames_final_data.pt` | 20 | 87% | ‚ö° Fast | Balanced (default) |
| `model_97_acc_100_frames_FF_data.pt` | 100 | **97%** ‚≠ê | üê¢ ~1 min | Best accuracy |

**Recommended**: Use the 100-frame model (97% accuracy) for critical applications.

---

## üìã Prerequisites

### System Requirements
- **GPU**: NVIDIA GPU with Compute Capability > 3.0 (strongly recommended)
- **CUDA**: Version >= 10.0 (for GPU support)
- **OS**: Windows, macOS, or Linux
- **RAM**: Minimum 8GB (16GB recommended)

### Software Requirements
- **Python**: 3.6 or higher
- **pip**: Package installer for Python
- **Git**: For cloning the repository

### Python Packages
See [requirements.txt](Django%20Application/requirements.txt) for full list. Main packages:
- Django >= 5.0
- PyTorch
- OpenCV
- Numpy, Pandas
- face-recognition
- matplotlib

---

## üöÄ Quick Start

### 1. Clone the Repository
```bash
git clone https://github.com/Zala0007/deepfake.git
cd deepfake
```

### 2. Navigate to Django Application
```bash
cd "Django Application"
```

### 3. Create Virtual Environment (Recommended)
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

### 4. Install Dependencies
```bash
pip install -r requirements.txt
```

### 5. Model 
model is our own creativity, we can't disclose it here..

### 6. Create Required Directories
```bash
mkdir media\videos
mkdir media\images
mkdir uploaded_videos
mkdir uploaded_images
```

### 7. Run Django Server
```bash
python manage.py runserver
```

### 8. Access the Application
Open your browser and go to: **http://localhost:8000/**

---

## üîß Detailed Installation

### Step 1: Clone Repository and Enter Directory
```bash
git clone https://github.com/Zala0007/deepfake.git
cd deepfake/"Django Application"
```

### Step 2: Set Up Python Environment
```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate
```

### Step 3: Install Python Dependencies
```bash
pip install --upgrade pip
pip install -r requirements.txt
```

**Note**: If you encounter issues with face-recognition or dlib:
- On Windows, you may need to install Build Tools for Visual Studio
- On macOS: `brew install cmake` then `pip install dlib`

### Step 4: Download Pre-trained Models
1. Create your own model and follow the next steps
2. Place in `Django Application/models/` directory

Available models:
which we have implemented
- `model_84_acc_10_frames_final_data.pt` (84% accuracy)
- `model_87_acc_20_frames_final_data.pt` (87% accuracy)
- `model_97_acc_100_frames_FF_data.pt` (97% accuracy - **Recommended**)

### Step 5: Prepare Directories
```bash
# Windows
mkdir media\videos
mkdir media\images
mkdir uploaded_videos
mkdir uploaded_images

# macOS/Linux
mkdir -p media/videos media/images uploaded_videos uploaded_images
```

### Step 6: Run Django Server
```bash
python manage.py runserver
```

Expected output:
```
Starting development server at http://127.0.0.1:8000/
Quit the server with CTRL-BREAK.
```

---

## üíª Running the Application

### Accessing the Web Interface
1. Open browser ‚Üí **http://localhost:8000/**
2. You should see the deepfake detection interface

### Using the Application

#### Step 1: Upload Video
- Click on "Upload Video" or navigate to prediction page
- Select a video file (MP4, AVI, MOV, etc.)

#### Step 2: Select Frame Count
- **10 frames**: Fastest (84% accuracy) - ~5-10 seconds
- **20 frames**: Balanced (87% accuracy) - ~10-15 seconds
- **100 frames**: Most accurate (97% accuracy) - ~30-60 seconds

**Recommendation**: Use 100 frames for best accuracy

#### Step 3: Submit for Analysis
- Click "Predict" or "Upload"
- Wait for processing (duration depends on frame count)

#### Step 4: View Results
- See prediction result: **Real** or **Fake**
- Confidence scores and visualization

### Troubleshooting Application

**Problem**: Page not loading
- **Solution**: Ensure Django server is running on http://localhost:8000/

**Problem**: Model not found error
- **Solution**: Verify model files are in `Django Application/models/` directory

**Problem**: Slow processing (GPU not being used)
- **Solution**: 
  - Check CUDA installation: `python -c "import torch; print(torch.cuda.is_available())"`
  - Should return `True` for GPU support
  - If `False`, reinstall PyTorch with CUDA support

---

## üê≥ Docker Setup

### Prerequisites
- Docker Desktop installed
- NVIDIA GPU with Docker support (nvidia-docker)


## üß† Model Training

To train your own deepfake detection model:

### Using Jupyter Notebooks
1. Navigate to `Model Creation/` directory
2. Open Jupyter Lab:
```bash
jupyter lab
```

3. Follow notebooks in order:
   - **1. preprocessing.ipynb** - Data preprocessing and preparation
   - **2. Model_and_train_csv.ipynb** - Model architecture and training
   - **3. Predict.ipynb** - Model evaluation and prediction

### Key Steps
1. Prepare dataset with labeled real and fake videos
2. Extract frames from videos
3. Feature extraction using ResNext
4. LSTM training on extracted features
5. Model evaluation and testing

### Training Data Structure
```
data/
‚îú‚îÄ‚îÄ real/
‚îÇ   ‚îú‚îÄ‚îÄ video1.mp4
‚îÇ   ‚îú‚îÄ‚îÄ video2.mp4
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ fake/
    ‚îú‚îÄ‚îÄ video1.mp4
    ‚îú‚îÄ‚îÄ video2.mp4
    ‚îî‚îÄ‚îÄ ...
```

---

## üìä Results

### Model Performance

| Model | Accuracy | Precision | Recall | F1-Score |
|-------|----------|-----------|--------|----------|
| 10-frame | 84% | 0.82 | 0.86 | 0.84 |
| 20-frame | 87% | 0.85 | 0.89 | 0.87 |
| 100-frame | **97%** | **0.96** | **0.98** | **0.97** |

### Key Findings
- More frames = Higher accuracy
- 100 frames optimal balance between accuracy and processing time
- ResNext + LSTM effective for temporal deepfake detection

---

## üêõ Troubleshooting

### Common Issues and Solutions

#### 1. CUDA/GPU Not Found
```bash
# Check CUDA availability
python -c "import torch; print(torch.cuda.is_available())"

# If False, reinstall PyTorch with CUDA support
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

#### 2. ModuleNotFoundError
```bash
# Reinstall all dependencies
pip install --upgrade -r requirements.txt
```

#### 3. Model Loading Error
- Verify model files exist in `Django Application/models/`
- Check file permissions
- Ensure correct model file names

#### 4. Out of Memory (OOM) Error
- Use fewer frames (10 or 20 instead of 100)
- Close other applications
- Increase system RAM or use cloud GPU

#### 5. Django Migration Issues
```bash
python manage.py migrate
python manage.py createsuperuser
```

#### 6. Port Already in Use
```bash
# Use different port
python manage.py runserver 8001
```


## üîí Security & Limitations

### Important Considerations
- **Accuracy Limitations**: Model accuracy varies based on video quality, resolution, and deepfake sophistication
- **False Positives/Negatives**: No system is 100% accurate; always use as one part of verification strategy
- **Adversarial Examples**: Advanced deepfakes may fool the model; research ongoing
- **Privacy**: Ensure you have proper consent before analyzing videos of individuals
- **Data Storage**: Videos are temporarily stored; implement proper data retention policies

### Ethical Use
- Use this tool responsibly for legitimate purposes (research, content verification, security)
- Respect privacy and consent of individuals in videos
- Do not use for malicious purposes

---

## üìã Changelog

### Version 2.0 (January 2026)
- ‚úÖ Updated to Django 5.0+
- ‚úÖ Added 97% accuracy model (100-frame model)
- ‚úÖ Enhanced UI with Bootstrap
- ‚úÖ Improved GPU acceleration
- ‚úÖ Added frame selection slider
- ‚úÖ Better error handling and user feedback
- ‚úÖ Docker support added

### Version 1.0 (Original)
- Initial release with 10 and 20 frame models
- Basic Django web interface
- CPU and GPU support

---

## ü§ù Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

### Ways to Contribute
- Report bugs and issues
- Suggest new features
- Improve documentation
- Optimize code
- Add new model architectures
- Improve model accuracy
- Create tutorials or guides

---

## üìÑ Citation

If you use this project in your research, please cite:

```bibtex
@software{deepfake_detection_2026,
  title = {Deepfake Detection Using Deep Learning (ResNext and LSTM)},
  author = {Zala0007},
  year = {2026},
  url = {https://github.com/Zala0007/deepfake}
}
```

---

**Last Updated**: January 2026  
**Version**: 2.0  
**Status**: Active Maintenance

**Made with ‚ù§Ô∏è for deepfake detection research and security**
